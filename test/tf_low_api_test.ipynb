{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low API test of TensorFlow\n",
    "---\n",
    "To satisify the purpose of copy all the `variables` from one **nn** to another **nn**\n",
    "We need to use low API(tensor, variables) to build a **nn** from scratch and test the copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the low level TensorFlow API the ability of copying the weights\n",
    "\n",
    "Unfortunately, the high level of TF cannot copy the weights of NN by value.\n",
    "\n",
    "Thus, we have to use the low API approach to copy the weights directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_actions = 1\n",
    "num_features = 1\n",
    "state = tf.constant([[1], [2], [3], [4]], dtype=tf.float32)#tf.placeholder(tf.float32, [None, num_features], name=\"state\")\n",
    "y_true = tf.constant([[0], [-1], [-2], [-3]], dtype=tf.float32)\n",
    "\n",
    "with tf.variable_scope(\"predict_net\"):\n",
    "    collections = [\"predict_net_params\", tf.GraphKeys.GLOBAL_VARIABLES]\n",
    "    num_nodes = 10\n",
    "    # weight_initializer = tf.random_normal_initializer(0, 0.3)\n",
    "    weight_initializer = tf.constant_initializer(value=1, dtype=tf.float32)\n",
    "    bias_initializer = tf.constant_initializer(0.1)\n",
    "\n",
    "    with tf.variable_scope(\"layer1\"):\n",
    "        layer1_weight = tf.get_variable(name=\"weight\", shape=[num_features, num_nodes],\n",
    "                                        initializer=weight_initializer, collections=collections)\n",
    "        layer1_bias = tf.get_variable(name=\"bias\", shape=[1, num_nodes], initializer=bias_initializer,\n",
    "                                      collections=collections)\n",
    "        layer1 = tf.nn.relu(tf.matmul(state, layer1_weight) + layer1_bias)\n",
    "        \n",
    "    with tf.variable_scope(\"layer2\"):\n",
    "        layer2_weight = tf.get_variable(name=\"weight\", shape=[num_nodes, num_actions],\n",
    "                                        initializer=weight_initializer, collections=collections)\n",
    "        layer2_bias = tf.get_variable(name=\"bias\", shape=[1, num_actions], initializer=bias_initializer,\n",
    "                                      collections=collections)\n",
    "        q_predict = tf.nn.relu(tf.matmul(layer1, layer2_weight) + layer2_bias)\n",
    "    \n",
    "with tf.variable_scope(\"target_net\"):\n",
    "    collections = [\"target_net_params\", tf.GraphKeys.GLOBAL_VARIABLES]\n",
    "    num_nodes = 10\n",
    "    # weight_initializer = tf.random_normal_initializer(0, 0.3)\n",
    "    weight_initializer = tf.zeros_initializer()\n",
    "    bias_initializer = tf.constant_initializer(0.1)\n",
    "\n",
    "    with tf.variable_scope(\"layer1\"):\n",
    "        layer1_weight = tf.get_variable(name=\"weight\", shape=[num_features, num_nodes],\n",
    "                                        initializer=weight_initializer, collections=collections)\n",
    "        layer1_bias = tf.get_variable(name=\"bias\", shape=[1, num_nodes], initializer=bias_initializer,\n",
    "                                      collections=collections)\n",
    "        layer1 = tf.nn.relu(tf.matmul(state, layer1_weight) + layer1_bias)\n",
    "        \n",
    "    with tf.variable_scope(\"layer2\"):\n",
    "        layer2_weight = tf.get_variable(name=\"weight\", shape=[num_nodes, num_actions],\n",
    "                                        initializer=weight_initializer, collections=collections)\n",
    "        layer2_bias = tf.get_variable(name=\"bias\", shape=[1, num_actions], initializer=bias_initializer,\n",
    "                                      collections=collections)\n",
    "        q_target = tf.nn.relu(tf.matmul(layer1, layer2_weight) + layer2_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.100001]\n [21.1     ]\n [31.1     ]\n [41.099995]]\n[[0.1]\n [0.1]\n [0.1]\n [0.1]]\n"
     ]
    }
   ],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "# Initialise the variables( weights & bias ), have to do before any sess.run()\n",
    "sess.run(init_op)\n",
    "print(sess.run(q_predict))\n",
    "print(sess.run(q_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test variables assignment by hand\n",
    "\n",
    "To copy the varibles from predict NN to target NN we need to copy the weights periodically, thus make follow test. High level API for tf cannot perform copy by value, unfortunately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "assignment_tf = tf.constant(value=[1], shape=[11, 11], dtype=tf.float32)\n",
    "print(sess.run(assignment_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_variable = tf.get_variable(name=\"test\", shape=[11, 11], dtype=tf.float32, initializer=tf.zeros_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(test_variable.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "assign_op = tf.assign(ref=test_variable, value=assignment_tf)\n",
    "sess.run(assign_op)\n",
    "print(sess.run(test_variable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test to assign a value to variables in side of NN and make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'predict_net/layer1/weight:0' shape=(1, 10) dtype=float32_ref>\n<tf.Variable 'target_net/layer1/weight:0' shape=(1, 10) dtype=float32_ref>\n<tf.Variable 'predict_net/layer1/bias:0' shape=(1, 10) dtype=float32_ref>\n<tf.Variable 'target_net/layer1/bias:0' shape=(1, 10) dtype=float32_ref>\n<tf.Variable 'predict_net/layer2/weight:0' shape=(10, 1) dtype=float32_ref>\n<tf.Variable 'target_net/layer2/weight:0' shape=(10, 1) dtype=float32_ref>\n<tf.Variable 'predict_net/layer2/bias:0' shape=(1, 1) dtype=float32_ref>\n<tf.Variable 'target_net/layer2/bias:0' shape=(1, 1) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "# Noted, here return a list of tf\n",
    "target_variables = tf.get_collection(\"target_net_params\")\n",
    "predict_variables = tf.get_collection(\"predict_net_params\")\n",
    "for predict_variable, target_variable in zip(predict_variables, target_variables):\n",
    "    print(predict_variable)\n",
    "    print(target_variable)\n",
    "\n",
    "# target_variables.assign(predict_variables)\n",
    "# sess.run(assign_op)\n",
    "# print(target_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.100001]\n [21.1     ]\n [31.1     ]\n [41.099995]]\n"
     ]
    }
   ],
   "source": [
    "for predict_variable, target_variable in zip(predict_variables, target_variables):\n",
    "    assign_op = tf.assign(ref=target_variable, value=predict_variable)\n",
    "    sess.run(assign_op)\n",
    "print(sess.run(q_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test training prediction NN won't affect the variables inside target NN\n",
    "Now after assignment, we just need a further test to ensure that it works\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "913.0099\n"
     ]
    }
   ],
   "source": [
    "loss = tf.losses.mean_squared_error(labels=y_true, predictions=q_predict)\n",
    "print(sess.run(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "913.0099\n447.41913\n278.79083\n194.47527\n145.21652\n113.55751\n91.834\n76.194824\n64.51275\n55.527016\n48.448147\n42.759583\n38.110817\n34.25666\n31.02114\n28.275074\n25.921791\n23.887686\n22.115868\n20.561762\n19.19001\n17.972261\n16.88555\n15.911096\n15.03343\n14.239693\n13.519127\n12.862677\n12.262663\n11.712551\n11.206728\n10.740374\n10.309311\n9.909855\n9.538421\n9.192185\n8.8688\n8.566196\n8.282532\n8.016171\n"
     ]
    }
   ],
   "source": [
    "optimiser = tf.train.GradientDescentOptimizer(0.001)\n",
    "train = optimiser.minimize(loss)\n",
    "for i in range(40):\n",
    "    _, loss_value = sess.run((train, loss))\n",
    "    print(loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        ]\n [0.39366665]\n [0.9546255 ]\n [1.5155843 ]]\n[[11.100001]\n [21.1     ]\n [31.1     ]\n [41.099995]]\n"
     ]
    }
   ],
   "source": [
    "# Train make prediction with 2 nn, we will have different value.\n",
    "print(sess.run(q_predict))\n",
    "print(sess.run(q_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5d4ec21bd0bd5b51c213ceda84d3d5c0da037d84"
      },
      "cell_type": "code",
      "source": "import gym\nimport tensorflow as tf\nimport matplotlib.pyplot as plt",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2b0ae68eae344414e7e7a9c52ebf69d4ea65c2dd"
      },
      "cell_type": "code",
      "source": "%matplotlib inline\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 15, 10",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "510a2f8ecc5f88466a2aa46aa8aaf094d4c3db56"
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a653ffda7e5158a8f46494794ab35a5e91a650b3"
      },
      "cell_type": "code",
      "source": "import timeit",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a21fbf2e152bfde57fbf8892dec12aa1381ec729"
      },
      "cell_type": "code",
      "source": "tf.test.gpu_device_name()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "e3187882447fca81987e89a2212cb1d022754984"
      },
      "cell_type": "code",
      "source": "env = gym.make(\"Taxi-v2\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d7a674050aff0e638c2d2d292a49dca9e3c038bf"
      },
      "cell_type": "code",
      "source": "class Experience:\n    CURRENT_STATE = 0\n    ACTION = 1\n    REWARD = 2\n    NEXT_STATE = 3\n    DONE = 4",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4f126a166530738ec0c7f9ced0a20bca084841de"
      },
      "cell_type": "code",
      "source": "# def create_net(input_state, variable_scope, layer_list, trainable, action_num):\n#     with tf.variable_scope(variable_scope):\n#         w_initialiser = tf.random_normal_initializer(mean=0., stddev=0.01)\n# #         layer1 = tf.layers.Dense(units=500, activation=tf.nn.relu,\n# #                                  name=\"layer\", trainable=trainable,\n# #                                 kernel_initializer=w_initialiser)\n# #         layer_list.append(layer1)\n# #         layer1_output = layer1(input_state)\n# #         layer2 = tf.layers.Dense(units=5, activation=tf.nn.relu,\n# #                                  name=\"layer\", trainable=trainable)\n# #         layer_list.append(layer2)\n# #         layer2_output = layer2(layer1_output)\n#         output_layer = tf.layers.Dense(units=action_num, name=\"layer\", \n#                                        trainable=trainable, kernel_initializer=w_initialiser,\n#                                        activation=None\n#                                       )\n#         layer_list.append(output_layer)\n#         output = output_layer(input_state)\n\n#         return output\n    \ndef create_net(input_state, variable_scope, variable_list, trainable):\n    with tf.variable_scope(variable_scope):\n        # =========== layer 1 ===========\n        weights_1 = tf.get_variable(name=\"w1\",\n                                    initializer=tf.random_uniform([env.observation_space.n, 6],0,0.01),\n#                                     initializer=tf.random_normal(shape=[env.observation_space.n, 6], stddev= (2/ env.observation_space.n)),\n                                    trainable=trainable\n                                   )\n        variable_list.append(weights_1)\n        \n        # ========== layer 2 =============\n#         weights_2 = tf.get_variable(name=\"w2\",\n# #                                     initializer=tf.random_uniform([6, env.action_space.n],0,0.01),\n#                                     initializer=tf.random_normal(shape=[6, env.action_space.n], stddev= (2/ (env.observation_space.n ** 2))),\n#                                     trainable=trainable\n#                                    )\n#         variable_list.append(weights_2)\n        \n#         bias = tf.get_variable(name=\"b1\",\n#                                shape=[6],\n#                                initializer=tf.constant_initializer(0.01),\n#                                trainable=trainable\n#                               )\n#         variable_list.append(bias)\n        \n#         layer1_output = tf.nn.elu(tf.matmul(input_state, weights_1))\n#         output = tf.matmul(layer1_output, weights_2)\n        \n        output = tf.matmul(input_state, weights_1) #+ bias\n        \n        return output",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "394acb1a307bd9fb18ac056ed9685b241a0cb778"
      },
      "cell_type": "code",
      "source": "def copy_net(dest_list, src_list, sess):\n    for predict_variable, target_variable in zip(src_list, dest_list):\n        assign_op = tf.assign(ref=target_variable, value=predict_variable)\n        sess.run(assign_op)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1c2edefc59699fa8335c24c676a0a609591341fe"
      },
      "cell_type": "markdown",
      "source": "## Create the neural network\n---"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "69bf99ff8debe9e02fc4aaa42e98135972ba5dbf"
      },
      "cell_type": "code",
      "source": "tf.reset_default_graph()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6f485bd9669b10e11046bb707172d48b9b9191a7"
      },
      "cell_type": "code",
      "source": "predict_input_state_tf = tf.placeholder(shape=(None, env.observation_space.n), dtype= tf.float32, name=\"predict_input_state\")\ntarget_input_state_tf = tf.placeholder(shape=(None, env.observation_space.n), dtype=tf.float32, name=\"target_input_state\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "361e2582138320470b75c552f8be9094910c65b1"
      },
      "cell_type": "code",
      "source": "predict_variable_list = []\npredict_q_values_tf = create_net(predict_input_state_tf, variable_scope=\"predict_net\",\n                                 variable_list=predict_variable_list, trainable=True)\n\npredict_action_tf = tf.argmax(predict_q_values_tf, axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9ad56fc6b8585fff0d8e82123df6c748dee8af46"
      },
      "cell_type": "code",
      "source": "target_variable_list = []\ntarget_q_values_tf = create_net(target_input_state_tf, variable_scope=\"target_net\",\n                                 variable_list=target_variable_list, trainable=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d8a1c157b7f34d16b8fd5f1b1080f03d77796e28"
      },
      "cell_type": "code",
      "source": "y_tf = tf.placeholder(shape=(None, env.action_space.n), dtype=tf.float32)\n\nwith tf.variable_scope(\"loss\"):\n#     loss_tf = tf.losses.mean_squared_error(labels=y_tf, predictions=predict_q_values_tf)\n    loss_tf = tf.losses.huber_loss(labels=y_tf, predictions=predict_q_values_tf) # Clip the error according to the journal\n\n#     loss_tf = tf.reduce_sum(tf.squared_difference(y_tf, predict_q_values_tf))\nwith tf.variable_scope(\"train\"):\n#     my_optimiser = tf.train.GradientDescentOptimizer(2.2)\n    my_optimiser = tf.train.RMSPropOptimizer(learning_rate = 0.4)\n#     my_optimiser = tf.train.RMSPropOptimizer(learning_rate = 0.3, momentum=0.95, epsilon=0.01)\n#     my_optimiser = tf.train.MomentumOptimizero(learning_rate = 1.2, momentum = 0.9)\n    train_op = my_optimiser.minimize(loss_tf)\n#     for variables in predict_variable_list:\n#         gradients_op_list.append(my_optimiser.compute_gradients(loss_tf, var_list=variables))\n    grads_and_vars_op = my_optimiser.compute_gradients(loss_tf, var_list=predict_variable_list)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5400c44a13a8a0b627cf3da753ea37b886a28a8b"
      },
      "cell_type": "code",
      "source": "init_op = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init_op)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0f3ec91eea3c879bbadc9fcdd3bb9c64fa9d50cc"
      },
      "cell_type": "markdown",
      "source": "### Copy the initial network"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ac0abc2736cf7c247093f98c84b7d49f986ffee6"
      },
      "cell_type": "code",
      "source": "copy_net(src_list=predict_variable_list, dest_list=target_variable_list, sess=sess)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e91bbfe293cfbc27b6d36639fae378ae0e7f40db"
      },
      "cell_type": "code",
      "source": "for variable in predict_variable_list:\n    predict_mat = sess.run(variable)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0a4572feb301f78148cf699c0d7c09256be08dc4"
      },
      "cell_type": "code",
      "source": "for variable in target_variable_list:\n    target_mat = sess.run(variable)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b274cbf07865027ea192d1f733691d4f27396a0f"
      },
      "cell_type": "code",
      "source": "np.unique(predict_mat - target_mat)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "be757c692433d0c44d279cfaa74a9dc6562fb13f"
      },
      "cell_type": "markdown",
      "source": "## Set up hyperparameters"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "33f2db41d400dddb07e246bdfae4bd8c46706328"
      },
      "cell_type": "code",
      "source": "max_random_probability = 1.0\nmin_random_probability = 0\nmem_size = 3000\nupdate_epoches = 50\nbatch_size = 32\ngamma = 0.99\none_hot_state = np.identity(env.observation_space.n)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "010f6bc438704e8106bd43d317c797db5cc3f10f"
      },
      "cell_type": "markdown",
      "source": "## Experience replay\nCreate the memory"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ca0eb507c979054c5133c600f549ae328f676f44"
      },
      "cell_type": "code",
      "source": "mem = np.zeros((mem_size, 5), dtype=np.int32)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e5511cb0cf90382cdbbb7f4b81dc4a0c9322686b"
      },
      "cell_type": "code",
      "source": "def store_experience(first_start, current_state, action, reward, next_state, done):\n    # index point to the oldest experience\n    if first_start:\n        current_idx = 0\n\n    \"\"\"\n    Memory is full, replace the oldest one\n\n    The complexity of fetching a element from deque is horrible,\n    while pop the front of list is also slow(everything after \n    that must move), thus we keep track the oldest value and\n    replace it since, sequence is not important(random pick)\n    \"\"\"\n    mem[current_idx] = [current_state, action, reward, next_state, done]\n    if current_idx == (mem_size - 1):  # Reach the max size\n        current_idx = 0\n    else:\n        current_idx += 1\n        \n    return current_idx",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8e2c32e201885753871cedb13c1e35fb08d9d3ab"
      },
      "cell_type": "markdown",
      "source": "## Start training the network"
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "4c483e4f7710cdd527886f8a6f6441db1b4c9012"
      },
      "cell_type": "code",
      "source": "sess.run(loss_tf, feed_dict={\n    y_tf: [[1,2,3,4,5,6]], \n    predict_input_state_tf: np.identity(500)[0:1]\n})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cf9da9e1ce9578ad26c86f677fe8b5bd8f648f68"
      },
      "cell_type": "code",
      "source": "saver = tf.train.Saver()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "_uuid": "87a4d8128ef8e5e82bf20a26d60e25a3bcfd7a88"
      },
      "cell_type": "code",
      "source": "loss_list = []\nreward_list = []\nsteps_list = []\n\ngradient_list = []\nmean_variable_list = []\nstd_variable_list = []\n# Always point to the oldest experience in mem\n\ncopy_time_list = []\ntraining_time_list = []\n\nfirst_start = True\n\nepisode_num = 1000\nrandom_probability_distribution = np.linspace(max_random_probability, min_random_probability, episode_num * 0.9)\nlearn_epochs_counter = 0\n\nstart = timeit.default_timer()\nfor i in range(episode_num):\n    done = False\n    episode_reward = 0\n    current_state = env.reset()\n    step_counter = 0\n    random_probability = random_probability_distribution[i] if i < len(random_probability_distribution) else 0\n    \n    while step_counter < 100: # If agent cannot find the solution in 50 steps reset the environment\n        [action], predict_q_values = sess.run([predict_action_tf, predict_q_values_tf],\n                                              feed_dict={\n                                                  predict_input_state_tf: one_hot_state[current_state: current_state + 1]\n                                              })        \n        \n        if np.random.uniform() <= random_probability:\n            # Randomly explore the world\n            action = env.action_space.sample()\n        \n\n        # Execute the action and observe the reward\n        next_state, reward, done, info = env.step(action)\n        \n         # Store the experience to memory\n        current_idx = store_experience(\n            first_start=first_start,\n            current_state=current_state,\n            action=action,\n            reward=reward,\n            next_state=next_state,\n            done=done\n        )\n        \n        if current_idx > batch_size:\n            first_start = False\n        \n        # Randomly select batch size experiences from memory\n        if first_start:\n            indices = range(current_idx)\n        else:\n            indices = np.random.choice(mem_size, batch_size, replace=False)\n        \n        # Get the batch size experiences out of memory\n        batch_mem = mem[indices, :]\n        next_state_indices = batch_mem[:, Experience.NEXT_STATE]\n        current_state_indices = batch_mem[:, Experience.CURRENT_STATE]\n        \n        \n        # use the target network to calculate the next q values\n        next_q_values = sess.run(target_q_values_tf, feed_dict={\n            target_input_state_tf: one_hot_state[next_state_indices]\n        })\n        \n        # Pick the max q value for next state\n        max_next_q_value = np.max(next_q_values, axis=1)\n        # Take the other actions q values\n        y = predict_q_values\n        # Update the right we performed only\n#         y[np.arange(len(y)), batch_mem[:, Experience.ACTION]] = reward + gamma * max_next_q_value\n        y[np.arange(len(y)), batch_mem[:, Experience.ACTION]] = batch_mem[:, Experience.REWARD] + (1 - batch_mem[:, Experience.DONE]) * gamma * max_next_q_value\n        \n        # Learn CPU: 53.27853714457888\n        training_start = timeit.default_timer()\n        _, grads_and_vars,loss = sess.run([train_op, grads_and_vars_op, loss_tf], feed_dict={\n#             predict_input_state_tf: one_hot_state[current_state: current_state + 1],\n            predict_input_state_tf: one_hot_state[current_state_indices],\n            y_tf: y\n        })\n        training_end = timeit.default_timer()\n        \n        training_time_list.append(training_end - training_start)\n        \n        # Increment this after each learning\n        learn_epochs_counter += 1\n        \n        loss_list.append(loss)\n        for pair in grads_and_vars:\n            gradient_list.append(np.mean(pair[0]))\n            mean_variable_list.append(np.mean(pair[1]))\n            std_variable_list.append(np.std(pair[1]))        \n        \n        \n        current_state = next_state\n        \n        episode_reward += reward\n        step_counter += 1\n        \n        # Update the target network every 100 learning epochs\n        if learn_epochs_counter % update_epoches == 0 and learn_epochs_counter != 0:\n            copy_start = timeit.default_timer()\n            copy_net(src_list=predict_variable_list, dest_list=target_variable_list, sess=sess)\n            copy_end = timeit.default_timer()\n            copy_time_list.append(copy_end - copy_start)\n        \n        if i >= (episode_num - 1):\n            env.render()\n            print(loss)\n            \n        if done:\n            break\n    \n    reward_list.append(episode_reward)\n    steps_list.append(step_counter)\n    \n    if i and i%200 == 0:\n        print(\"Episode: {0},  step: {1}, random: {2}\".format(i, step_counter, random_probability))\nend = timeit.default_timer()\n\nprint(\"Time usage: \", end - start, \" seconds\") # Total 189.60779396699218\nprint(\"Copy time average usage: \", np.sum(copy_time_list), \" seconds\")\nprint(\"Training time average usage: \", np.sum(training_time_list), \" seconds\")\n# save_path = saver.save(sess, \"/obj/model.ckpt\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e8960eccd6ff4f57bcdde77946c9b20c4b669145"
      },
      "cell_type": "markdown",
      "source": "## Evaluate the performance"
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true,
        "_uuid": "57b108fd341636b1b874d75e8d229cd0f02f5e0d"
      },
      "cell_type": "code",
      "source": "print(np.mean(reward_list))\nplt.plot(reward_list)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7bbe8bd1f246037300bd713e39c5679abef8bd00"
      },
      "cell_type": "code",
      "source": "print(np.mean(steps_list))\nplt.plot(steps_list)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5451cddfd2a6a750d3010babfb6cf40180cbc479"
      },
      "cell_type": "code",
      "source": "plt.plot(loss_list)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9e938b8c2182de5e1eff50c43a7a655abaf6ff95"
      },
      "cell_type": "code",
      "source": "plt.plot(gradient_list)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f19e64137afeb211c6c1d1771bb2ec3f6ec11d9a"
      },
      "cell_type": "code",
      "source": "plt.plot(mean_variable_list)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fe0bdfd11520f3836345c93488b127d3bdb0c3bb"
      },
      "cell_type": "code",
      "source": "plt.plot(std_variable_list)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "537ff99e28a16a18dc5854c52a802f445b2350fc"
      },
      "cell_type": "markdown",
      "source": "## Evaluate with the real q table"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3837fc983a0ab811a77d1cd1ce72fa402e4d5c18"
      },
      "cell_type": "code",
      "source": "import pickle\n\nq_table = pickle.load(open(\"obj/q_table.pkl\", \"rb\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ef534d483322a44bd0d2389b9d2247aaec286685"
      },
      "cell_type": "markdown",
      "source": "Using the `DQN` predicts the whole table"
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "f621d7931826a7ccc6d29de63baf39e8221104d9"
      },
      "cell_type": "code",
      "source": "predict_q_table = sess.run(predict_q_values_tf, feed_dict={predict_input_state_tf: one_hot_state})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false,
        "_uuid": "f518e26a09df81021eb3ccce8e3dca6493a4de01"
      },
      "cell_type": "code",
      "source": "np.mean(np.absolute(predict_q_table - q_table))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "326b0873bcfef96b2606ebda2d78b1917c93cede"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}